// src/hooks/rag/useRagLlmAnalysis.js
/**
 * RAG LLM ë¶„ì„ ê´€ë¦¬ Custom Hook
 * - LLM ê°€ìš©ì„± í™•ì¸, ë¶„ì„ ì‘ì—… ê´€ë¦¬
 * - ì›ë˜ ë²„ê·¸ ìˆ˜ì •: checkLlmAvailabilityì—ì„œ getAuthHeaders is not defined ì—ëŸ¬ í•´ê²°
 */
import { useCallback } from 'react';
import { useAppContext } from '../../context/AppContext.jsx';
import { API_CONFIG } from '../../utils/apiConstants.js';

import { debugLog } from '../../utils/logger.js';

const IS_RAG_ENABLED = import.meta.env.VITE_ENABLE_RAG !== 'false' && import.meta.env.VITE_USE_DEMO_DATA !== 'true';

export function useRagLlmAnalysis(state, dispatch, ActionTypes, ensureRagAvailable, requestCache) {
    const { api } = useAppContext();

    // ============ LLM ê°€ìš©ì„± í™•ì¸ â­ (ì›ë˜ ë²„ê·¸ ìˆ˜ì •!) ============
    const checkLlmAvailability = useCallback(async () => {
        if (!IS_RAG_ENABLED) {
            dispatch({ type: ActionTypes.SET_LLM_AVAILABLE, payload: false });
            return false;
        }

        const cacheKey = 'checkLlmAvailability';
        if (requestCache && requestCache.current.has(cacheKey)) {
            debugLog('useRagLlmAnalysis', 'Skipping duplicate checkLlmAvailability call');
            return requestCache.current.get(cacheKey);
        }

        const promise = (async () => {
            dispatch({ type: ActionTypes.SET_LLM_CHECK_LOADING, payload: true });
            dispatch({ type: ActionTypes.CLEAR_ERROR });

            try {
                // ğŸ”§ ìˆ˜ì •: api()ë¥¼ ì‚¬ìš©í•˜ì—¬ ìë™ í† í° ê´€ë¦¬
                const response = await api('/api/llm-configs/check-availability');

                if (!response.ok) {
                    throw new Error('LLM ì„¤ì • í™•ì¸ ì‹¤íŒ¨');
                }

                const result = await response.json();
                const isAvailable = result.data === true;

                dispatch({ type: ActionTypes.SET_LLM_AVAILABLE, payload: isAvailable });

                if (!isAvailable) {
                    dispatch({
                        type: ActionTypes.SET_ERROR,
                        payload: 'ê¸°ë³¸ LLM ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤. AI ì§ˆì˜ì‘ë‹µì„ ì‚¬ìš©í•˜ë ¤ë©´ ê´€ë¦¬ìê°€ LLMì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.',
                    });
                }
                return isAvailable;
            } catch (error) {
                console.error('LLM ê°€ìš©ì„± í™•ì¸ ì‹¤íŒ¨:', error);
                dispatch({ type: ActionTypes.SET_LLM_AVAILABLE, payload: false });
                dispatch({
                    type: ActionTypes.SET_ERROR,
                    payload: error.message || 'LLM ì„¤ì • í™•ì¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
                });
                return false;
            } finally {
                requestCache.current.delete(cacheKey);
                dispatch({ type: ActionTypes.SET_LLM_CHECK_LOADING, payload: false });
            }
        })();

        if (requestCache) {
            requestCache.current.set(cacheKey, promise);
        }
        return promise;

    }, [api, dispatch, ActionTypes, requestCache]);

    // ============ LLM ë¶„ì„ ë¹„ìš© ì¶”ì • ============
    const estimateAnalysisCost = useCallback(async (documentId, config = {}) => {
        ensureRagAvailable('estimateAnalysisCost');
        debugLog('useRagLlmAnalysis', 'estimateAnalysisCost called with:', { documentId, config });

        try {
            const response = await api(
                `/api/rag/documents/${documentId}/estimate-cost`,
                {
                    method: 'POST',
                    body: JSON.stringify({
                        document_id: documentId,
                        llmConfigId: config.llmConfigId, // Backend DTO expects camelCase for this field (no @JsonProperty annotation)
                        llm_provider: config.llmProvider,
                        llm_model: config.llmModel,
                        prompt_template: config.promptTemplate,
                        max_tokens: config.maxTokens,
                    }),
                }
            );

            if (!response.ok) {
                throw new Error('ë¹„ìš© ì¶”ì • ìš”ì²­ ì‹¤íŒ¨');
            }

            const data = await response.json();
            debugLog('useRagLlmAnalysis', 'estimateAnalysisCost response:', data);
            return data;
        } catch (error) {
            console.error('ë¹„ìš© ì¶”ì • ì‹¤íŒ¨:', error);
            dispatch({
                type: ActionTypes.SET_ERROR,
                payload: error.message || 'ë¹„ìš© ì¶”ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'
            });
            throw error;
        }
    }, [api, ensureRagAvailable, dispatch, ActionTypes]);

    // ============ LLM ë¶„ì„ ì‹œì‘ ============
    const startLlmAnalysis = useCallback(async (documentId, config = {}) => {
        ensureRagAvailable('startLlmAnalysis');

        try {
            const response = await api(
                `/api/rag/documents/${documentId}/analyze-with-llm`,
                {
                    method: 'POST',
                    body: JSON.stringify({
                        llmConfigId: config.llmConfigId,
                        llm_provider: config.llmProvider,
                        llm_model: config.llmModel,
                        llm_base_url: config.llmBaseUrl,
                        prompt_template: config.promptTemplate,
                        chunk_batch_size: config.chunkBatchSize || 10,
                        pause_after_batch: config.pauseAfterBatch !== false,
                        max_tokens: config.maxTokens,
                        temperature: config.temperature || 0.7,
                    })
                }
            );

            if (!response.ok) {
                throw new Error('LLM ë¶„ì„ ì‹œì‘ ìš”ì²­ ì‹¤íŒ¨');
            }

            return await response.json();
        } catch (error) {
            console.error('LLM ë¶„ì„ ì‹œì‘ ì‹¤íŒ¨:', error);
            dispatch({
                type: ActionTypes.SET_ERROR,
                payload: error.message || 'LLM ë¶„ì„ ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'
            });
            throw error;
        }
    }, [api, ensureRagAvailable, dispatch, ActionTypes]);

    // ============ LLM ë¶„ì„ ìƒíƒœ ì¡°íšŒ ============
    const getLlmAnalysisStatus = useCallback(async (documentId) => {
        ensureRagAvailable('getLlmAnalysisStatus');

        try {
            const response = await api(`/api/rag/documents/${documentId}/llm-analysis-status`);
            return await response.json();
        } catch (error) {
            console.error('ë¶„ì„ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨:', error);
            throw error;
        }
    }, [api, ensureRagAvailable]);

    // ============ LLM ë¶„ì„ ì‘ì—… ëª©ë¡ ============
    const listLlmAnalysisJobs = useCallback(async (projectId = null, status = null, page = 1, size = 20) => {
        ensureRagAvailable('listLlmAnalysisJobs');

        try {
            // Build query parameters object, only including non-null values
            const params = new URLSearchParams();
            if (projectId) params.append('projectId', projectId);
            if (status) params.append('status', status);
            params.append('page', page);
            params.append('size', size);

            const url = `/api/rag/llm-analysis/jobs?${params.toString()}`;
            const response = await api(url);
            return await response.json();
        } catch (error) {
            console.error('ë¶„ì„ ì‘ì—… ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', error);
            throw error;
        }
    }, [api, ensureRagAvailable]);

    // ============ ë¶„ì„ ì¼ì‹œì •ì§€ ============
    const pauseAnalysis = useCallback(async (documentId) => {
        ensureRagAvailable('pauseAnalysis');

        try {
            const response = await api(
                `/api/rag/documents/${documentId}/pause-analysis`,
                { method: 'POST', body: JSON.stringify({}) }
            );
            return await response.json();
        } catch (error) {
            console.error('ë¶„ì„ ì¼ì‹œì •ì§€ ì‹¤íŒ¨:', error);
            dispatch({
                type: ActionTypes.SET_ERROR,
                payload: error.message || 'ë¶„ì„ ì¼ì‹œì •ì§€ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
            });
            throw error;
        }
    }, [api, ensureRagAvailable, dispatch, ActionTypes]);

    // ============ ë¶„ì„ ì¬ê°œ ============
    const resumeAnalysis = useCallback(async (documentId) => {
        ensureRagAvailable('resumeAnalysis');

        try {
            const response = await api(
                `/api/rag/documents/${documentId}/resume-analysis`,
                { method: 'POST', body: JSON.stringify({}) }
            );
            return await response.json();
        } catch (error) {
            console.error('ë¶„ì„ ì¬ê°œ ì‹¤íŒ¨:', error);
            dispatch({
                type: ActionTypes.SET_ERROR,
                payload: error.message || 'ë¶„ì„ ì¬ê°œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
            });
            throw error;
        }
    }, [api, ensureRagAvailable, dispatch, ActionTypes]);

    // ============ ë¶„ì„ ì·¨ì†Œ ============
    const cancelAnalysis = useCallback(async (documentId) => {
        ensureRagAvailable('cancelAnalysis');

        try {
            const response = await api(
                `/api/rag/documents/${documentId}/cancel-analysis`,
                { method: 'POST', body: JSON.stringify({}) }
            );
            return await response.json();
        } catch (error) {
            console.error('ë¶„ì„ ì·¨ì†Œ ì‹¤íŒ¨:', error);
            dispatch({
                type: ActionTypes.SET_ERROR,
                payload: error.message || 'ë¶„ì„ ì·¨ì†Œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
            });
            throw error;
        }
    }, [api, ensureRagAvailable, dispatch, ActionTypes]);

    // ============ LLM ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ============
    const getLlmAnalysisResults = useCallback(async (documentId, skip = 0, limit = 50) => {
        ensureRagAvailable('getLlmAnalysisResults');

        try {
            const url = `/api/rag/documents/${documentId}/llm-analysis-results?skip=${skip}&limit=${limit}`;
            const response = await api(url);
            return await response.json();
        } catch (error) {
            console.error('ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨:', error);
            dispatch({
                type: ActionTypes.SET_ERROR,
                payload: error.response?.data?.message || 'ë¶„ì„ ê²°ê³¼ ì¡°íšŒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
            });
            throw error;
        }
    }, [api, ensureRagAvailable, dispatch, ActionTypes]);

    // ============ ë¶„ì„ ìš”ì•½ ìƒì„± ============
    const createAnalysisSummary = useCallback(async (summaryData) => {
        ensureRagAvailable('createAnalysisSummary');

        try {
            const response = await api(
                '/api/rag/analysis-summaries',
                {
                    method: 'POST',
                    body: JSON.stringify(summaryData),
                }
            );
            return await response.json();
        } catch (error) {
            console.error('ë¶„ì„ ìš”ì•½ ìƒì„± ì‹¤íŒ¨:', error);
            dispatch({
                type: ActionTypes.SET_ERROR,
                payload: error.message || 'ë¶„ì„ ìš”ì•½ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
            });
            throw error;
        }
    }, [api, ensureRagAvailable, dispatch, ActionTypes]);

    // ============ ë¶„ì„ ìš”ì•½ ì¡°íšŒ ============
    const getAnalysisSummary = useCallback(async (summaryId) => {
        ensureRagAvailable('getAnalysisSummary');

        try {
            const response = await api(`/api/rag/analysis-summaries/${summaryId}`);
            return await response.json();
        } catch (error) {
            console.error('ë¶„ì„ ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨:', error);
            throw error;
        }
    }, [api, ensureRagAvailable]);

    // ============ ë¶„ì„ ìš”ì•½ ëª©ë¡ ì¡°íšŒ ============
    const listAnalysisSummaries = useCallback(async (filters = {}) => {
        ensureRagAvailable('listAnalysisSummaries');

        try {
            const queryParams = new URLSearchParams(filters).toString();
            const url = `/api/rag/analysis-summaries${queryParams ? `?${queryParams}` : ''}`;
            const response = await api(url);
            return await response.json();
        } catch (error) {
            console.error('ë¶„ì„ ìš”ì•½ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', error);
            throw error;
        }
    }, [api, ensureRagAvailable]);

    // ============ ë¶„ì„ ìš”ì•½ ìˆ˜ì • ============
    const updateAnalysisSummary = useCallback(async (summaryId, summaryData) => {
        ensureRagAvailable('updateAnalysisSummary');

        try {
            const response = await api(
                `/api/rag/analysis-summaries/${summaryId}`,
                {
                    method: 'PUT',
                    body: JSON.stringify(summaryData),
                }
            );
            return await response.json();
        } catch (error) {
            console.error('ë¶„ì„ ìš”ì•½ ìˆ˜ì • ì‹¤íŒ¨:', error);
            dispatch({
                type: ActionTypes.SET_ERROR,
                payload: error.message || 'ë¶„ì„ ìš”ì•½ ìˆ˜ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
            });
            throw error;
        }
    }, [api, ensureRagAvailable, dispatch, ActionTypes]);

    // ============ ë¶„ì„ ìš”ì•½ ì‚­ì œ ============
    const deleteAnalysisSummary = useCallback(async (summaryId) => {
        ensureRagAvailable('deleteAnalysisSummary');

        try {
            await api(`/api/rag/analysis-summaries/${summaryId}`, { method: 'DELETE' });
        } catch (error) {
            console.error('ë¶„ì„ ìš”ì•½ ì‚­ì œ ì‹¤íŒ¨:', error);
            dispatch({
                type: ActionTypes.SET_ERROR,
                payload: error.message || 'ë¶„ì„ ìš”ì•½ ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
            });
            throw error;
        }
    }, [api, ensureRagAvailable, dispatch, ActionTypes]);

    return {
        checkLlmAvailability,
        estimateAnalysisCost,
        startLlmAnalysis,
        getLlmAnalysisStatus,
        listLlmAnalysisJobs,
        pauseAnalysis,
        resumeAnalysis,
        cancelAnalysis,
        getLlmAnalysisResults,
        createAnalysisSummary,
        getAnalysisSummary,
        listAnalysisSummaries,
        updateAnalysisSummary,
        deleteAnalysisSummary,
    };
}

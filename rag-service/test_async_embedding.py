#!/usr/bin/env python3
"""
Test script for asynchronous embedding generation

This script tests that the RAG service can handle multiple concurrent requests
while embedding generation is in progress.

í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤:
1. ë¬¸ì„œ ì—…ë¡œë“œ
2. ë¬¸ì„œ ë¶„ì„ (ì²­í¬ ìƒì„±)
3. ì„ë² ë”© ìƒì„± ì‹œì‘ (ë¹„ë™ê¸°)
4. ì„ë² ë”© ì§„í–‰ ì¤‘ì—ë„ ë‹¤ë¥¸ API ìš”ì²­ì´ ì •ìƒ ì²˜ë¦¬ë˜ëŠ”ì§€ í™•ì¸
5. ì„ë² ë”© ìƒíƒœ ì¡°íšŒ API í…ŒìŠ¤íŠ¸
"""

import asyncio
import aiohttp
import time
import uuid
from datetime import datetime

RAG_API_URL = "http://localhost:8001/api/v1"


async def upload_document(session, project_id=None):
    """ë¬¸ì„œ ì—…ë¡œë“œ"""
    print("\nğŸ“¤ Step 1: Uploading test document...")

    # UUID ìƒì„± (project_idê°€ ì—†ìœ¼ë©´)
    if not project_id:
        project_id = str(uuid.uuid4())
        print(f"   Generated project_id: {project_id}")

    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ìƒì„±
    test_content = "\n\n".join([
        f"Test Paragraph {i}: " + ("This is a test sentence. " * 20)
        for i in range(10)  # 10ê°œ ë¬¸ë‹¨ ìƒì„±
    ])

    data = aiohttp.FormData()
    data.add_field('file',
                   test_content.encode('utf-8'),
                   filename='test_async.txt',
                   content_type='text/plain')
    data.add_field('project_id', str(project_id))
    data.add_field('uploaded_by', 'test-user')

    async with session.post(f"{RAG_API_URL}/documents/upload", data=data) as response:
        if response.status in [200, 201]:
            result = await response.json()
            doc_id = result.get('id') or result.get('document_id')
            print(f"âœ… Document uploaded: {doc_id}")
            return doc_id
        else:
            text = await response.text()
            print(f"âŒ Upload failed: {response.status} - {text}")
            return None


async def analyze_document(session, doc_id):
    """ë¬¸ì„œ ë¶„ì„ (ì²­í¬ ìƒì„±)"""
    print(f"\nğŸ” Step 2: Analyzing document {doc_id}...")

    payload = {
        "parser_mode": "pymupdf4llm",
        "chunk_size": 500,
        "chunk_overlap": 50
    }

    async with session.post(f"{RAG_API_URL}/documents/{doc_id}/analyze", json=payload) as response:
        if response.status in [200, 202]:
            result = await response.json()
            print(f"âœ… Document analysis started (async)")

            # ë¶„ì„ ì™„ë£Œê¹Œì§€ ëŒ€ê¸° (ìµœëŒ€ 30ì´ˆ)
            for i in range(30):
                await asyncio.sleep(1)
                async with session.get(f"{RAG_API_URL}/documents/{doc_id}") as doc_response:
                    if doc_response.status == 200:
                        doc_data = await doc_response.json()
                        if doc_data.get('analysis_status') == 'completed':
                            # ì²­í¬ ê°œìˆ˜ ì¡°íšŒ
                            async with session.get(f"{RAG_API_URL}/documents/{doc_id}/chunks") as chunks_response:
                                if chunks_response.status == 200:
                                    chunks_data = await chunks_response.json()
                                    total_chunks = chunks_data.get('total', 0)
                                    print(f"âœ… Document analyzed: {total_chunks} chunks created")
                                    return total_chunks
                        elif doc_data.get('analysis_status') == 'failed':
                            print(f"âŒ Analysis failed")
                            return 0

            print("âš ï¸  Analysis timeout")
            return 0
        else:
            text = await response.text()
            print(f"âŒ Analysis failed: {response.status} - {text}")
            return 0


async def start_embedding(session, doc_id):
    """ì„ë² ë”© ìƒì„± ì‹œì‘ (ë¹„ë™ê¸°)"""
    print(f"\nâš¡ Step 3: Starting embedding generation for {doc_id}...")

    payload = {"document_id": doc_id}

    start_time = time.time()
    async with session.post(f"{RAG_API_URL}/embeddings/generate", json=payload) as response:
        response_time = time.time() - start_time

        if response.status == 202:
            result = await response.json()
            print(f"âœ… Embedding generation started (response time: {response_time:.3f}s)")
            print(f"   Message: {result['message']}")
            print(f"   Total chunks: {result['total_chunks']}")
            return True
        else:
            text = await response.text()
            print(f"âŒ Embedding start failed: {response.status} - {text}")
            return False


async def check_embedding_status(session, doc_id):
    """ì„ë² ë”© ìƒíƒœ ì¡°íšŒ"""
    async with session.get(f"{RAG_API_URL}/embeddings/status/{doc_id}") as response:
        if response.status == 200:
            return await response.json()
        else:
            return None


async def test_concurrent_requests(session, doc_id):
    """ì„ë² ë”© ì§„í–‰ ì¤‘ ë‹¤ë¥¸ ìš”ì²­ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ”„ Step 4: Testing concurrent requests while embedding is in progress...")

    # ì—¬ëŸ¬ ìš”ì²­ì„ ë™ì‹œì— ì‹¤í–‰
    tasks = []

    # 1. ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ
    tasks.append(session.get(f"{RAG_API_URL}/documents/"))

    # 2. ë¬¸ì„œ ìƒì„¸ ì •ë³´ ì¡°íšŒ
    tasks.append(session.get(f"{RAG_API_URL}/documents/{doc_id}"))

    # 3. ì²­í¬ ëª©ë¡ ì¡°íšŒ
    tasks.append(session.get(f"{RAG_API_URL}/documents/{doc_id}/chunks?skip=0&limit=10"))

    # 4. ì„ë² ë”© ìƒíƒœ ì¡°íšŒ
    tasks.append(session.get(f"{RAG_API_URL}/embeddings/status/{doc_id}"))

    start_time = time.time()
    responses = await asyncio.gather(*tasks, return_exceptions=True)
    total_time = time.time() - start_time

    success_count = 0
    for i, response in enumerate(responses):
        if isinstance(response, Exception):
            print(f"   âŒ Request {i+1} failed: {response}")
        elif response.status == 200:
            success_count += 1
            print(f"   âœ… Request {i+1} succeeded ({response.status})")
        else:
            print(f"   âš ï¸  Request {i+1} returned {response.status}")

    print(f"\nğŸ“Š Concurrent request results:")
    print(f"   - Total requests: {len(tasks)}")
    print(f"   - Successful: {success_count}")
    print(f"   - Total time: {total_time:.3f}s")
    print(f"   - Average time: {total_time/len(tasks):.3f}s per request")

    return success_count == len(tasks)


async def monitor_embedding_progress(session, doc_id, check_interval=2, max_duration=60):
    """ì„ë² ë”© ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§"""
    print(f"\nğŸ‘€ Step 5: Monitoring embedding progress...")

    start_time = time.time()
    last_status = None

    while True:
        elapsed = time.time() - start_time
        if elapsed > max_duration:
            print(f"\nâš ï¸  Timeout after {max_duration}s")
            break

        status_data = await check_embedding_status(session, doc_id)
        if not status_data:
            print("   âŒ Failed to get status")
            await asyncio.sleep(check_interval)
            continue

        current_status = status_data.get('status')
        progress = status_data.get('progress_percentage', 0)
        embedded = status_data.get('embedded_chunks', 0)
        total = status_data.get('total_chunks', 0)

        if current_status != last_status:
            print(f"\n   ğŸ“ Status changed: {last_status} â†’ {current_status}")
            last_status = current_status

        print(f"   [{datetime.now().strftime('%H:%M:%S')}] "
              f"Progress: {progress:.1f}% ({embedded}/{total} chunks) - {current_status}")

        if current_status == "completed":
            print(f"\nâœ… Embedding generation completed!")
            if 'completed_at' in status_data:
                print(f"   Completed at: {status_data['completed_at']}")
            break
        elif current_status == "failed":
            print(f"\nâŒ Embedding generation failed!")
            if 'error_message' in status_data:
                print(f"   Error: {status_data['error_message']}")
            break

        await asyncio.sleep(check_interval)

    return last_status == "completed"


async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("=" * 70)
    print("ğŸ§ª Testing Asynchronous Embedding Generation")
    print("=" * 70)

    async with aiohttp.ClientSession() as session:
        # Step 1: ë¬¸ì„œ ì—…ë¡œë“œ
        doc_id = await upload_document(session)
        if not doc_id:
            return False

        # Step 2: ë¬¸ì„œ ë¶„ì„
        chunk_count = await analyze_document(session, doc_id)
        if chunk_count == 0:
            return False

        # Step 3: ì„ë² ë”© ìƒì„± ì‹œì‘ (ë¹„ë™ê¸°)
        if not await start_embedding(session, doc_id):
            return False

        # Step 4: ì„ë² ë”© ì§„í–‰ ì¤‘ ë‹¤ë¥¸ ìš”ì²­ í…ŒìŠ¤íŠ¸
        concurrent_success = await test_concurrent_requests(session, doc_id)

        # Step 5: ì„ë² ë”© ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
        embedding_success = await monitor_embedding_progress(session, doc_id)

        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 70)
        print("ğŸ“‹ Test Results Summary")
        print("=" * 70)
        print(f"âœ… Document upload:              SUCCESS")
        print(f"âœ… Document analysis:            SUCCESS ({chunk_count} chunks)")
        print(f"âœ… Async embedding start:        SUCCESS")
        print(f"{'âœ…' if concurrent_success else 'âŒ'} Concurrent requests:         {'SUCCESS' if concurrent_success else 'FAILED'}")
        print(f"{'âœ…' if embedding_success else 'âŒ'} Embedding completion:        {'SUCCESS' if embedding_success else 'FAILED'}")
        print("=" * 70)

        return concurrent_success and embedding_success


if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)
